{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Classification Tutorial\n",
    "Neural Netorks using Tensorflow 2.0  \n",
    "Patrick Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "x_train = x_train[10000:]\n",
    "y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13bdea4f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 0 # You may select anything up to 60,000\n",
    "#print(img_names[y_train[image_index][0]]) # Print the label\n",
    "plt.imshow(x_train[image_index], cmap='Greys') # Show the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing\n",
    "Scaling all values to be between 0-1 for gradient descent to work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = (x_val.astype('float32') / 255.0)\n",
    "x_train = (x_train.astype('float32') / 255.0)\n",
    "x_test = (x_test.astype('float32') / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Neural Network\n",
    "Create an arbitrary sequential neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[28,28]),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dense(300, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(10, activation='softmax') # Use softmax for output for classification of > 2 items\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 583,385\n",
      "Trainable params: 583,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7454 - accuracy: 0.7686 - val_loss: 0.2491 - val_accuracy: 0.9254\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1897 - accuracy: 0.9428 - val_loss: 0.1617 - val_accuracy: 0.9517\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1264 - accuracy: 0.9622 - val_loss: 0.1335 - val_accuracy: 0.9622\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0935 - accuracy: 0.9726 - val_loss: 0.1570 - val_accuracy: 0.9562\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0722 - accuracy: 0.9781 - val_loss: 0.1074 - val_accuracy: 0.9684\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0555 - accuracy: 0.9835 - val_loss: 0.1020 - val_accuracy: 0.9701\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0434 - accuracy: 0.9873 - val_loss: 0.1037 - val_accuracy: 0.9714\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0322 - accuracy: 0.9910 - val_loss: 0.1512 - val_accuracy: 0.9591\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0260 - accuracy: 0.9924 - val_loss: 0.0976 - val_accuracy: 0.9718\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.1027 - val_accuracy: 0.9729\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.1006 - val_accuracy: 0.9751\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.1007 - val_accuracy: 0.9748\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.1008 - val_accuracy: 0.9761\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.1027 - val_accuracy: 0.9768\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1030 - val_accuracy: 0.9769\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.1055 - val_accuracy: 0.9764\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 9.5345e-04 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9766\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 7.6983e-04 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9766\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 6.6097e-04 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9764\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 5.7425e-04 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9760\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 5.0204e-04 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9761\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.3976e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9764\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0586e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9764\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.6751e-04 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9760\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.4231e-04 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9769\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.0676e-04 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9762\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.8231e-04 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9766\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6365e-04 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9766\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.4480e-04 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9766\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.2997e-04 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1074484f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=30, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model Accuracy\n",
    "97.85% accuracy is achieved on the test dataset. Not bad with so little code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11545068025588989, 0.9785000085830688]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
